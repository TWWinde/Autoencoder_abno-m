
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, UpSampling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.models import save_model
import tensorflow as tf

import matplotlib.pyplot as plt
import numpy as np
import random
import glob
from sklearn.neighbors import KernelDensity
import os

import keras
from keras.layers import Dense, Activation, Flatten, Input

import matplotlib.pyplot as plt
from keras import backend as K
from PIL import Image, ImageChops


# Size of our input images
SIZE = 96

batch_size = 32
train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')

train_generator = train_datagen.flow_from_directory(
    'gazebo_images/normal_train',
    target_size=(SIZE, SIZE),
    batch_size=batch_size,
    class_mode='input'
    )

test_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')
validation_generator = test_datagen.flow_from_directory(
    'gazebo_images/normal_test',
    target_size=(SIZE, SIZE),
    batch_size=batch_size,
    class_mode='input'
    )

anomaly_generator = test_datagen.flow_from_directory(
    '/home/zilin/keras_anomaly_detection/gazebo_images/faulty',
    target_size=(SIZE, SIZE),
    batch_size=batch_size,
    class_mode='input'
    )

# Define the autoencoder. 
# Try to make the bottleneck layer size as small as possible to make it easy for
# density calculations and also picking appropriate thresholds. 

model = Sequential()

model.add(Conv2D(16, (3, 3), padding='same',activation='relu', input_shape=(96, 96, 3)))
model.add(MaxPooling2D(pool_size=(4,4), padding='same')) # using pool_size (4,4) makes the layer 4x smaller in height and width

model.add(Conv2D(8,(3, 3),activation='relu',  padding='same'))
model.add(MaxPooling2D(pool_size=(4,4), padding='same'))

model.add(Conv2D(3,(3, 3),activation='relu',  padding='same'))
model.add(MaxPooling2D(pool_size=(2,2), padding='same'))

#-------------------------
model.add(Conv2D(3,(3, 3),activation='relu',  padding='same'))
model.add(UpSampling2D((2, 2)))

model.add(Conv2D(8,(3, 3),activation='relu',  padding='same'))
model.add(UpSampling2D((4, 4)))

model.add(Conv2D(16,(3, 3),activation='relu',  padding='same'))
model.add(UpSampling2D((4, 4)))

model.add(Conv2D(3,(3, 3), activation='sigmoid', padding='same'))
#-------------------------

model.summary()

optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
# Compile the model
model.compile(optimizer=optimizer, loss='mean_squared_error')

es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30) # Early stopping (stops training when validation doesn't improve for {patience} epochs)
model_filepath = 'models/model1.keras'
save_best = keras.callbacks.ModelCheckpoint(model_filepath, monitor='val_loss', save_best_only=True, mode='min') # Saves the best version of the model to disk (as measured on the validation data set)


# Fit the model. 
history = model.fit_generator(
        train_generator,
        steps_per_epoch=300 // batch_size,
        epochs=40,
        validation_data=validation_generator,
        validation_steps=80 // batch_size,
        shuffle = True,
        callbacks=[es, save_best])


# Plot the training and validation accuracy and loss at each epoch
#plot the training and validation accuracy and loss at each epoch
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

model.save('my_model.h5')


# Get all batches generated by the datagen and pick a batch for prediction
# Just to test the model. 
# 获取数据根生成的所有批次，并选择一个批次进行预测
# 只是为了测试模型。
data_batch = []  # Capture all training batches as a numpy array
img_num = 0
while img_num <= train_generator.batch_index:   # Gets each generated batch of size batch_size
    data = train_generator.next()
    data_batch.append(data[0])
    img_num = img_num + 1

predicted = model.predict(data_batch[0])  # Predict on the first batch of images


# Sanity check, view few images and corresponding reconstructions
# 正确性检查，查看几幅图像和相应的重建图像
image_number = random.randint(0, predicted.shape[0])
plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.imshow(data_batch[0][image_number])
plt.subplot(122)
plt.imshow(predicted[image_number])
plt.show()


# # Let us examine the reconstruction error between our validation data (good/normal images)
# # And the anomaly images
# # 让我们检查验证数据（良好/正常图像）与异常图像之间的重建误差
# # 和异常图像
# validation_error = model.evaluate_generator(validation_generator)
# anomaly_error = model.evaluate_generator(anomaly_generator)

# print("Recon. error for the validation (normal) data is: ", validation_error)
# print("Recon. error for the anomaly data is: ", anomaly_error)


# # Let us extract (or build) the encoder network, with trained weights.
# # This is used to get the compressed output (latent space) of the input image. 
# # The compressed output is then used to calculate the KDE
# # 让我们提取（或构建）带有训练过的权重的编码器网络。
# # 这将用于获取输入图像的压缩输出（潜空间）。
# # 压缩后的输出用于计算 KDE

# encoder_model = Sequential()
# encoder_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3), weights=model.layers[0].get_weights()) )
# encoder_model.add(MaxPooling2D((2, 2), padding='same'))
# encoder_model.add(Conv2D(32, (3, 3), activation='relu', padding='same', weights=model.layers[2].get_weights()))
# encoder_model.add(MaxPooling2D((2, 2), padding='same'))
# encoder_model.add(Conv2D(16, (3, 3), activation='relu', padding='same', weights=model.layers[4].get_weights()))
# encoder_model.add(MaxPooling2D((2, 2), padding='same'))
# encoder_model.summary()


# ########################################################
# # Calculate KDE using sklearn

# # Get encoded output of input images = Latent space
# encoded_images = encoder_model.predict_generator(train_generator)

# # Flatten the encoder output because KDE from sklearn takes 1D vectors as input
# # 由于 sklearn 的 KDE 将一维向量作为输入，因此将encoder输出变平
# encoder_output_shape = encoder_model.output_shape # Here, we have 16x16x16
# out_vector_shape = encoder_output_shape[1]*encoder_output_shape[2]*encoder_output_shape[3]

# encoded_images_vector = [np.reshape(img, (out_vector_shape)) for img in encoded_images]

# # Fit KDE to the image latent data  ## 将 KDE 与图像潜数据拟合
# kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(encoded_images_vector)

# # Calculate density and reconstruction error to find their means values for
# # Good and anomaly images. 
# # We use these mean and sigma to set thresholds. 

# # 计算密度和重建误差，找出其平均值。
# # 正常图像和异常图像的平均值。
# # 我们使用这些平均值和 sigma 值来设置阈值。

# def calc_density_and_recon_error(batch_images):
    
#     density_list=[]
#     recon_error_list=[]
#     for im in range(0, batch_images.shape[0]-1):
        
#         img  = batch_images[im]
#         img = img[np.newaxis, :,:,:]
#         encoded_img = encoder_model.predict([[img]]) # Create a compressed version of the image using the encoder
#         encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] # Flatten the compressed image
#         density = kde.score_samples(encoded_img)[0] # get a density score for the new image
#         reconstruction = model.predict([[img]])
#         reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]
#         density_list.append(density)
#         recon_error_list.append(reconstruction_error)
        
#     average_density = np.mean(np.array(density_list))  
#     stdev_density = np.std(np.array(density_list)) 
    
#     average_recon_error = np.mean(np.array(recon_error_list))  
#     stdev_recon_error = np.std(np.array(recon_error_list)) 
    
#     return average_density, stdev_density, average_recon_error, stdev_recon_error

# # Get average and std dev. of density and recon. error for uninfected and anomaly (parasited) images. 
# # For this let us generate a batch of images for each. 
# # 获取正常图像和异常图像的密度和重组误差的平均值和标准差。
# # 为此，让我们分别生成一批图像。

# train_batch = train_generator.next()[0]
# anomaly_batch = anomaly_generator.next()[0]

# uninfected_values = calc_density_and_recon_error(train_batch)
# anomaly_values = calc_density_and_recon_error(anomaly_batch)


# # Now, input unknown images and sort as Good or Anomaly
# # 现在，输入未知图像并按 "良好 "或 "异常 "分类
# def check_anomaly(img_path):
#     density_threshold = 2500  # Set this value based on the above exercise
#     reconstruction_error_threshold = 0.004  # Set this value based on the above exercise
#     img  = Image.open(img_path)
#     img = np.array(img.resize((128,128), Image.ANTIALIAS))
#     plt.imshow(img)
#     img = img / 255.
#     img = img[np.newaxis, :,:,:]
#     encoded_img = encoder_model.predict([[img]]) 
#     encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] 
#     density = kde.score_samples(encoded_img)[0] 

#     reconstruction = model.predict([[img]])
#     reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]

#     if density < density_threshold or reconstruction_error > reconstruction_error_threshold:
#         print("The image is an anomaly")
        
#     else:
#         print("The image is NOT an anomaly")
        
        
# # Load a couple of test images and verify whether they are reported as anomalies.
# # 加载几个测试图像并验证它们是否被报告为异常。

# # para_file_paths = glob.glob('gazebo_images/faulty/images/*')
# # uninfected_file_paths = glob.glob('gazebo_images/normal_train/images/*')

# # # Anomaly image verification
# # num=random.randint(0,len(para_file_paths)-1)
# # check_anomaly(para_file_paths[num])

# # # Good/normal image verification
# # num=random.randint(0,len(para_file_paths)-1)
# # check_anomaly(uninfected_file_paths[num])